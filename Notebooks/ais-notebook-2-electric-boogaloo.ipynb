{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#Jayita Malik \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport pathlib\nimport random\nimport glob\n\n#CURRENT EPOCHS = 30\n#CURRENT BATCH = 32\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import preprocessing\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory\nfrom tensorflow.keras.layers.experimental.preprocessing import Rescaling\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.regularizers import l2 #Regulizer for overfitting\nimport PIL\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":110,"outputs":[]},{"cell_type":"code","source":"images_path = os.path.join(os.path.realpath('..'), \"input\", \"garbage-classification\", \"Garbage classification\", \"Garbage classification\")\nimages_path = pathlib.Path(images_path)\n\ntotal = len(list(images_path.glob('*/*.jpg')))\n\nprint(f\"total images: {total}\")\n\nbatch_size = 32\nprint(f\"batch size: {batch_size}\")\nimg_height = 180\nimg_width = 180\nrescale = Rescaling(scale=1.0/255)","metadata":{"trusted":true},"execution_count":111,"outputs":[{"name":"stdout","text":"total images: 2527\nbatch size: 32\n","output_type":"stream"}]},{"cell_type":"code","source":"train_ds = image_dataset_from_directory(\n  images_path,\n  validation_split=0.3,\n  subset=\"training\",\n  seed=1232376,\n  image_size=(img_height, img_width),\n  batch_size=batch_size)\n\ntrain_ds = train_ds.map(lambda image,label:(rescale(image),label))","metadata":{"trusted":true},"execution_count":112,"outputs":[{"name":"stdout","text":"Found 2527 files belonging to 6 classes.\nUsing 1769 files for training.\n","output_type":"stream"}]},{"cell_type":"code","source":"val_ds = image_dataset_from_directory(\n  images_path,\n  validation_split=0.3,\n  subset=\"validation\",\n  seed=1232376,\n  image_size=(img_height, img_width),\n  batch_size=batch_size)\n\nval_ds = val_ds.map(lambda image,label:(rescale(image),label))","metadata":{"trusted":true},"execution_count":113,"outputs":[{"name":"stdout","text":"Found 2527 files belonging to 6 classes.\nUsing 758 files for validation.\n","output_type":"stream"}]},{"cell_type":"code","source":"num_classes = 6\n\n#layers = 3\nmodel = tf.keras.Sequential([\n  #layers.Conv2D(16, 5, activation='relu'),\n  #layers.MaxPooling2D(pool_size=(2, 2)),\n  #layers.Dropout(0.20),  \n  \n  layers.Conv2D(32, 3, activation='relu'),\n  layers.MaxPooling2D(pool_size=(2, 2)),\n  layers.Dropout(0.20),    \n    \n  layers.Conv2D(32, 5, activation='relu'),\n  layers.MaxPooling2D(pool_size=(2, 2)),\n  layers.Dropout(0.20),   \n    \n  layers.Conv2D(32, 7, activation='relu'),\n  layers.MaxPooling2D(pool_size=(2, 2)),\n  layers.Dropout(0.20),   \n    \n  layers.Conv2D(64, 7, activation='relu'),\n  layers.MaxPooling2D(pool_size=(2, 2)),\n  layers.Dropout(0.20),  \n\n  layers.Conv2D(128, 5, activation='relu'),#Filter, kernel size \n  layers.MaxPooling2D(pool_size=(2, 2)),\n  layers.Dropout(0.20),  \n    \n  #layers.kernel_regularizer=l2(0.0005),  \n    \n  layers.Flatten(),\n  layers.Dense(64, activation='relu'),\n  #layers.Dense(128, activation='relu'),\n  #layers.Dense(128, activation='relu')  \n  layers.Dense(num_classes)\n])\n\nmodel.compile(\n  optimizer='adam',\n  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n  metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":114,"outputs":[]},{"cell_type":"code","source":"model.fit(\n  train_ds,\n  validation_data=val_ds,\n  batch_size=batch_size,  \n  epochs=30,\n  shuffle=True  #Turning the shuffle on \n)\n\nmodel.summary()","metadata":{"trusted":true},"execution_count":115,"outputs":[{"name":"stdout","text":"Epoch 1/30\n56/56 [==============================] - 8s 122ms/step - loss: 1.7583 - accuracy: 0.2052 - val_loss: 1.7431 - val_accuracy: 0.1807\nEpoch 2/30\n56/56 [==============================] - 7s 119ms/step - loss: 1.6883 - accuracy: 0.2438 - val_loss: 1.6970 - val_accuracy: 0.1807\nEpoch 3/30\n56/56 [==============================] - 7s 111ms/step - loss: 1.6419 - accuracy: 0.2834 - val_loss: 1.5174 - val_accuracy: 0.3483\nEpoch 4/30\n56/56 [==============================] - 7s 112ms/step - loss: 1.5937 - accuracy: 0.3226 - val_loss: 1.5139 - val_accuracy: 0.3681\nEpoch 5/30\n56/56 [==============================] - 7s 113ms/step - loss: 1.5312 - accuracy: 0.3501 - val_loss: 1.4583 - val_accuracy: 0.4393\nEpoch 6/30\n56/56 [==============================] - 7s 115ms/step - loss: 1.4707 - accuracy: 0.4216 - val_loss: 1.4458 - val_accuracy: 0.4380\nEpoch 7/30\n56/56 [==============================] - 7s 112ms/step - loss: 1.3981 - accuracy: 0.4311 - val_loss: 1.3557 - val_accuracy: 0.4644\nEpoch 8/30\n56/56 [==============================] - 7s 110ms/step - loss: 1.3451 - accuracy: 0.4672 - val_loss: 1.3401 - val_accuracy: 0.4657\nEpoch 9/30\n56/56 [==============================] - 7s 114ms/step - loss: 1.2984 - accuracy: 0.4869 - val_loss: 1.2228 - val_accuracy: 0.5251\nEpoch 10/30\n56/56 [==============================] - 7s 115ms/step - loss: 1.2468 - accuracy: 0.5275 - val_loss: 1.3273 - val_accuracy: 0.4697\nEpoch 11/30\n56/56 [==============================] - 7s 115ms/step - loss: 1.2793 - accuracy: 0.5024 - val_loss: 1.2562 - val_accuracy: 0.5449\nEpoch 12/30\n56/56 [==============================] - 7s 116ms/step - loss: 1.1904 - accuracy: 0.5419 - val_loss: 1.2895 - val_accuracy: 0.5145\nEpoch 13/30\n56/56 [==============================] - 7s 112ms/step - loss: 1.1886 - accuracy: 0.5408 - val_loss: 1.2171 - val_accuracy: 0.5303\nEpoch 14/30\n56/56 [==============================] - 7s 109ms/step - loss: 1.1079 - accuracy: 0.5783 - val_loss: 1.1534 - val_accuracy: 0.5673\nEpoch 15/30\n56/56 [==============================] - 7s 112ms/step - loss: 1.0129 - accuracy: 0.6163 - val_loss: 1.2400 - val_accuracy: 0.5449\nEpoch 16/30\n56/56 [==============================] - 7s 113ms/step - loss: 0.9755 - accuracy: 0.6300 - val_loss: 1.1270 - val_accuracy: 0.5897\nEpoch 17/30\n56/56 [==============================] - 7s 112ms/step - loss: 0.9067 - accuracy: 0.6534 - val_loss: 1.2353 - val_accuracy: 0.5594\nEpoch 18/30\n56/56 [==============================] - 7s 113ms/step - loss: 0.8866 - accuracy: 0.6619 - val_loss: 1.1452 - val_accuracy: 0.5910\nEpoch 19/30\n56/56 [==============================] - 7s 111ms/step - loss: 0.7807 - accuracy: 0.7145 - val_loss: 1.1916 - val_accuracy: 0.5910\nEpoch 20/30\n56/56 [==============================] - 7s 112ms/step - loss: 0.7790 - accuracy: 0.7234 - val_loss: 1.1508 - val_accuracy: 0.6121\nEpoch 21/30\n56/56 [==============================] - 7s 113ms/step - loss: 0.7095 - accuracy: 0.7434 - val_loss: 1.1745 - val_accuracy: 0.5871\nEpoch 22/30\n56/56 [==============================] - 7s 110ms/step - loss: 0.6969 - accuracy: 0.7495 - val_loss: 1.2753 - val_accuracy: 0.6069\nEpoch 23/30\n56/56 [==============================] - 7s 121ms/step - loss: 0.7872 - accuracy: 0.7147 - val_loss: 1.1017 - val_accuracy: 0.6240\nEpoch 24/30\n56/56 [==============================] - 7s 110ms/step - loss: 0.5649 - accuracy: 0.7917 - val_loss: 1.1242 - val_accuracy: 0.6412\nEpoch 25/30\n56/56 [==============================] - 7s 121ms/step - loss: 0.5141 - accuracy: 0.8051 - val_loss: 1.2080 - val_accuracy: 0.6346\nEpoch 26/30\n56/56 [==============================] - 7s 114ms/step - loss: 0.5324 - accuracy: 0.8183 - val_loss: 1.2037 - val_accuracy: 0.6240\nEpoch 27/30\n56/56 [==============================] - 7s 110ms/step - loss: 0.4479 - accuracy: 0.8312 - val_loss: 1.3044 - val_accuracy: 0.6280\nEpoch 28/30\n56/56 [==============================] - 7s 112ms/step - loss: 0.4675 - accuracy: 0.8253 - val_loss: 1.4765 - val_accuracy: 0.6214\nEpoch 29/30\n56/56 [==============================] - 7s 108ms/step - loss: 0.4727 - accuracy: 0.8336 - val_loss: 1.4032 - val_accuracy: 0.5976\nEpoch 30/30\n56/56 [==============================] - 7s 115ms/step - loss: 0.3685 - accuracy: 0.8533 - val_loss: 1.3294 - val_accuracy: 0.6478\nModel: \"sequential_18\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_93 (Conv2D)           (None, 178, 178, 32)      896       \n_________________________________________________________________\nmax_pooling2d_93 (MaxPooling (None, 89, 89, 32)        0         \n_________________________________________________________________\ndropout_93 (Dropout)         (None, 89, 89, 32)        0         \n_________________________________________________________________\nconv2d_94 (Conv2D)           (None, 85, 85, 32)        25632     \n_________________________________________________________________\nmax_pooling2d_94 (MaxPooling (None, 42, 42, 32)        0         \n_________________________________________________________________\ndropout_94 (Dropout)         (None, 42, 42, 32)        0         \n_________________________________________________________________\nconv2d_95 (Conv2D)           (None, 36, 36, 32)        50208     \n_________________________________________________________________\nmax_pooling2d_95 (MaxPooling (None, 18, 18, 32)        0         \n_________________________________________________________________\ndropout_95 (Dropout)         (None, 18, 18, 32)        0         \n_________________________________________________________________\nconv2d_96 (Conv2D)           (None, 12, 12, 64)        100416    \n_________________________________________________________________\nmax_pooling2d_96 (MaxPooling (None, 6, 6, 64)          0         \n_________________________________________________________________\ndropout_96 (Dropout)         (None, 6, 6, 64)          0         \n_________________________________________________________________\nconv2d_97 (Conv2D)           (None, 2, 2, 128)         204928    \n_________________________________________________________________\nmax_pooling2d_97 (MaxPooling (None, 1, 1, 128)         0         \n_________________________________________________________________\ndropout_97 (Dropout)         (None, 1, 1, 128)         0         \n_________________________________________________________________\nflatten_18 (Flatten)         (None, 128)               0         \n_________________________________________________________________\ndense_37 (Dense)             (None, 64)                8256      \n_________________________________________________________________\ndense_38 (Dense)             (None, 6)                 390       \n=================================================================\nTotal params: 390,726\nTrainable params: 390,726\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]}]}